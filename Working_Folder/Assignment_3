self.stack = ['ROOT']
self.buffer = sentence
self.dependencies = []

if transition == "S":
  self.stack.append(self.buffer[0])
  self.buffer = self.buffer[1:]
if transition == "LA":
  self.dependencies.append((self.stack[-1],self.stack[-2]))
  self.stack.pop(-2)
if transition == "RA":
  self.dependencies.append((self.stack[-2],self.stack[-1]))
  self.stack.pop(-1)
  

partial_parses = [PartialParse(sentence) for sentence in sentences]
unfinished_parses = partial_parses[:]
pbar = tqdm(total=len(unfinished_parses),desc='Parsing')
while len(unfinished_parses) > 0:
    mini_batch = unfinished_parses[:batch_size]
    for parser,parser_next_step in zip(mini_batch,model.predict(mini_batch)):
        parser.parse_step(parser_next_step)
        if parser.is_parsed():
            unfinished_parses.remove(parser)
            pbar.update(1)
dependencies = [parser.dependencies for parser in partial_parses]


## Pytorch - nn 
self.embed_to_hidden = torch.nn.Linear(embed_size*self.n_features,hidden_size)
self.embed_to_hidden.weight = nn.init.xavier_uniform_(self.embed_to_hidden.weight)
self.dropout = nn.Dropout(p=dropout_prob)
self.hidden_to_logits = torch.nn.Linear(hidden_size, n_classes, bias=True)
self.hidden_to_logits.weight = nn.init.xavier_uniform_(self.hidden_to_logits.weight)

x_embed = self.pretrained_embeddings(t)
x = x_embed.view(t.shape[0],-1)

embed_layer = self.embedding_lookup(t)
h1 = self.embed_to_hidden(embed_layer)
h1 = nn.functional.relu(h1)
do = self.dropout(h1)
logits = self.hidden_to_logits(do)

optimizer = torch.optim.Adam(parser.model.parameters(),lr=lr)
loss_func = nn.CrossEntropyLoss()  


logits = parser.model(train_x)
loss = loss_func(logits,train_y)
# Backward pass  Auto differntiation not much of an worry
loss.backward()
#Update using optimizer after calculating loss
optimizer.step()



## Assignment  - 4

max_len = np.max(np.array([len(sent) for sent in sample_l]))

for sent in sample_l:
  
  if len(sent) != max_len:
    
    while len(sent) < max_len:
      sent.append(pad_token)
          
  else:
     pass
     
self.source = torch.nn.Embedding(len(vocab.src), embed_size, padding_idx=src_pad_token_idx)
self.target = torch.nn.Embedding(len(vocab.tgt), embed_size, padding_idx=tgt_pad_token_idx)

self.encoder = nn.LSTM(input_size=embed_size, hidden_size=hidden_size,bidirectional= True)
self.decoder = nn.LSTM(input_size=embed_size+hidden_size, hidden_size=hidden_size,bidirectional= False)
self.h_projection = nn.Linear(2*hidden_size,hidden_size,bias=False)
self.c_projection = nn.Linear(2*hidden_size,hidden_size,bias=False)
self.att_projection =  nn.Linear(2*hidden_size,hidden_size,bias=False)
self.combined_output_projection  = nn.Linear(3*hidden_size,hidden_size,bias=False)
self.target_vocab_projection = nn.Linear(hidden_size,len(vocab.tgt),bias=False)
self.dropout = nn.Dropout(self.dropout_rate)


X = self.model_embeddings.source(source_padded)
X_pack = nn.utils.rnn.pack_padded_sequence(X,source_lengths,batch_first=False, enforce_sorted=True)
enc_hiddens, (last_hidden, last_cell) = self.encoder(X_pack)
nn.utils.rnn.pad_packed_sequence(enc_hiddens, batch_first=False, padding_value=0.0, total_length=None)
enc_hiddens = enc_hiddens.permute(1, 0, 2)
last_hidden = torch.cat((last_hidden[0],last_hidden[1]), 1)
init_decoder_hidden = self.h_projection(last_hidden)
last_cell  = torch.cat((last_cell[0],last_cell[1]),1)
init_decoder_cell = self.c_projection(last_cell)
dec_init_state = tuple(init_decoder_hidden,init_decoder_cell)


enc_hiddens_proj = self.att_projection (enc_hiddens)
Y = self.model_embeddings.source(target_padded)
for Y_t in torch.split(Y,1,dim=0):
          Y_t = torch.squeeze(Y_t)
          Ybar_t = torch.cat((Y_t,o_prev,) 1)
          dec_state, o_t, e_t  = step(Ybar_t,
                                                  dec_state,
                                                  enc_hiddens,
                                                  enc_hiddens_proj,
                                                  enc_masks)
          (dec_hidden, dec_cell) = dec_state
          combined_outputs.append(o_t)
          o_prev = o_t
          
combined_outputs = torch.stack(combined_outputs)

_,dec_state = self.decode(Ybar_t,dec_state)
(dec_hidden, dec_cell) = dec_state
un_dec_hidden = torch.unsqueeze(dec_hidden,2)
et = torch.bmm(enc_hiddens_proj,un_dec_hidden)
e_t = torch.squeeze(et,2)




alpha_t = F.softmax(e_t,1)
un_alpha_t = torch.unsqueeze(alpha_t,1)
a_t = torch.bmm(un_alpha_t,enc_hiddens)
a_t = torch.squeeze(a_t,1)
U_t = torch.cat(dec_hidden,a_t,1)
V_t = self.combined_output_projection(U_t)
O_t = self.dropout(torch.tanh(V_t))


